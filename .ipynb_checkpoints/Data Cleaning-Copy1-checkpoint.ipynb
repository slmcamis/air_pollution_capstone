{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Import Libraries](#Import-Libraries)\n",
    "1. [Obtain Data](#Obtain-Data)\n",
    "1. [Check For Nulls](#Check-For-Nulls)\n",
    "1. [Format Data](#Format-Data)\n",
    "1. [Standardize Column Names](#Standardize-Column-Names)\n",
    "1. [Filter observation_percent](#Filter-observation_percent)\n",
    "1. [Create Merge Column](#Create-Merge-Column)\n",
    "1. [Eliminate Duplicates in Merge Column](#Eliminate-Duplicates-in-Merge-Column)\n",
    "1. [Filter sample_duration](#Filter-sample_duration)\n",
    "1. [Aggregate data for merge_column](#Aggregate-data-for-merge_column)\n",
    "1. [Format AQI dataframe](#Format-AQI-dataframe)\n",
    "1. [Merge all dataframes](#Merge-all-dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data was downloaded from the EPA website and can be found here: https://aqs.epa.gov/aqsweb/airdata/download_files.html. The EPA only allows data to be pulled for one year at a time. I will use my `combine_annual_data` function to combine these yearly files into one big file. \n",
    "\n",
    "For the scope of this project, I have downloaded data for the 20 years from 2000 through 2019. At the time of this project, the quality of the data from the second half of 2019 has yet to be verified by the EPA. I may decide to drop half or all of 2019 during the EDA phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_annual_data(measure):\n",
    "    \"\"\"\n",
    "    Combines files for each year into one big file for given measure\n",
    "    \n",
    "    Input:\n",
    "    measure (string) - ['co2', 'so2', 'no2', 'o3', 'pm10', 'pm25', \n",
    "                        'aqi', 'pressure', 'temperature', 'wind']\n",
    "    \n",
    "    Output:\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    measure_codes = {'co2': '42101', 'so2': '42401', 'no2': '42602', 'o3': '44201', \n",
    "                     'pm10': '81102', 'pm25': '88101', 'aqi': 'aqi_by_county',\n",
    "                     'pressure': 'PRESS', 'temperature': 'TEMP', 'wind': 'WIND'}\n",
    "    prefix = 'all_data\\daily_'\n",
    "    code = measure_codes.get(measure)\n",
    "    suffix = '.csv'\n",
    "    filenames = []\n",
    "    for i in range(20):\n",
    "        year = 2000+i\n",
    "        file = prefix + code + '_' + str(year) + suffix\n",
    "        print(f'Adding file {file}')\n",
    "        filenames.append(file)\n",
    "    print('Combining files...')\n",
    "    df = pd.concat([pd.read_csv(f) for f in filenames], ignore_index = True)\n",
    "    print(f'Done! \\nShape of dataframe for {measure} for 2000-2019: {df.shape}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_42101_2000.csv\n",
      "Adding file all_data\\daily_42101_2001.csv\n",
      "Adding file all_data\\daily_42101_2002.csv\n",
      "Adding file all_data\\daily_42101_2003.csv\n",
      "Adding file all_data\\daily_42101_2004.csv\n",
      "Adding file all_data\\daily_42101_2005.csv\n",
      "Adding file all_data\\daily_42101_2006.csv\n",
      "Adding file all_data\\daily_42101_2007.csv\n",
      "Adding file all_data\\daily_42101_2008.csv\n",
      "Adding file all_data\\daily_42101_2009.csv\n",
      "Adding file all_data\\daily_42101_2010.csv\n",
      "Adding file all_data\\daily_42101_2011.csv\n",
      "Adding file all_data\\daily_42101_2012.csv\n",
      "Adding file all_data\\daily_42101_2013.csv\n",
      "Adding file all_data\\daily_42101_2014.csv\n",
      "Adding file all_data\\daily_42101_2015.csv\n",
      "Adding file all_data\\daily_42101_2016.csv\n",
      "Adding file all_data\\daily_42101_2017.csv\n",
      "Adding file all_data\\daily_42101_2018.csv\n",
      "Adding file all_data\\daily_42101_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for co2 for 2000-2019: (4976812, 29)\n"
     ]
    }
   ],
   "source": [
    "co = combine_annual_data('co2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_42401_2000.csv\n",
      "Adding file all_data\\daily_42401_2001.csv\n",
      "Adding file all_data\\daily_42401_2002.csv\n",
      "Adding file all_data\\daily_42401_2003.csv\n",
      "Adding file all_data\\daily_42401_2004.csv\n",
      "Adding file all_data\\daily_42401_2005.csv\n",
      "Adding file all_data\\daily_42401_2006.csv\n",
      "Adding file all_data\\daily_42401_2007.csv\n",
      "Adding file all_data\\daily_42401_2008.csv\n",
      "Adding file all_data\\daily_42401_2009.csv\n",
      "Adding file all_data\\daily_42401_2010.csv\n",
      "Adding file all_data\\daily_42401_2011.csv\n",
      "Adding file all_data\\daily_42401_2012.csv\n",
      "Adding file all_data\\daily_42401_2013.csv\n",
      "Adding file all_data\\daily_42401_2014.csv\n",
      "Adding file all_data\\daily_42401_2015.csv\n",
      "Adding file all_data\\daily_42401_2016.csv\n",
      "Adding file all_data\\daily_42401_2017.csv\n",
      "Adding file all_data\\daily_42401_2018.csv\n",
      "Adding file all_data\\daily_42401_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for so2 for 2000-2019: (6874455, 29)\n"
     ]
    }
   ],
   "source": [
    "so2 = combine_annual_data('so2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_42602_2000.csv\n",
      "Adding file all_data\\daily_42602_2001.csv\n",
      "Adding file all_data\\daily_42602_2002.csv\n",
      "Adding file all_data\\daily_42602_2003.csv\n",
      "Adding file all_data\\daily_42602_2004.csv\n",
      "Adding file all_data\\daily_42602_2005.csv\n",
      "Adding file all_data\\daily_42602_2006.csv\n",
      "Adding file all_data\\daily_42602_2007.csv\n",
      "Adding file all_data\\daily_42602_2008.csv\n",
      "Adding file all_data\\daily_42602_2009.csv\n",
      "Adding file all_data\\daily_42602_2010.csv\n",
      "Adding file all_data\\daily_42602_2011.csv\n",
      "Adding file all_data\\daily_42602_2012.csv\n",
      "Adding file all_data\\daily_42602_2013.csv\n",
      "Adding file all_data\\daily_42602_2014.csv\n",
      "Adding file all_data\\daily_42602_2015.csv\n",
      "Adding file all_data\\daily_42602_2016.csv\n",
      "Adding file all_data\\daily_42602_2017.csv\n",
      "Adding file all_data\\daily_42602_2018.csv\n",
      "Adding file all_data\\daily_42602_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for no2 for 2000-2019: (2829046, 29)\n"
     ]
    }
   ],
   "source": [
    "no2 = combine_annual_data('no2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_44201_2000.csv\n",
      "Adding file all_data\\daily_44201_2001.csv\n",
      "Adding file all_data\\daily_44201_2002.csv\n",
      "Adding file all_data\\daily_44201_2003.csv\n",
      "Adding file all_data\\daily_44201_2004.csv\n",
      "Adding file all_data\\daily_44201_2005.csv\n",
      "Adding file all_data\\daily_44201_2006.csv\n",
      "Adding file all_data\\daily_44201_2007.csv\n",
      "Adding file all_data\\daily_44201_2008.csv\n",
      "Adding file all_data\\daily_44201_2009.csv\n",
      "Adding file all_data\\daily_44201_2010.csv\n",
      "Adding file all_data\\daily_44201_2011.csv\n",
      "Adding file all_data\\daily_44201_2012.csv\n",
      "Adding file all_data\\daily_44201_2013.csv\n",
      "Adding file all_data\\daily_44201_2014.csv\n",
      "Adding file all_data\\daily_44201_2015.csv\n",
      "Adding file all_data\\daily_44201_2016.csv\n",
      "Adding file all_data\\daily_44201_2017.csv\n",
      "Adding file all_data\\daily_44201_2018.csv\n",
      "Adding file all_data\\daily_44201_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for o3 for 2000-2019: (7281203, 29)\n"
     ]
    }
   ],
   "source": [
    "o3 = combine_annual_data('o3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_81102_2000.csv\n",
      "Adding file all_data\\daily_81102_2001.csv\n",
      "Adding file all_data\\daily_81102_2002.csv\n",
      "Adding file all_data\\daily_81102_2003.csv\n",
      "Adding file all_data\\daily_81102_2004.csv\n",
      "Adding file all_data\\daily_81102_2005.csv\n",
      "Adding file all_data\\daily_81102_2006.csv\n",
      "Adding file all_data\\daily_81102_2007.csv\n",
      "Adding file all_data\\daily_81102_2008.csv\n",
      "Adding file all_data\\daily_81102_2009.csv\n",
      "Adding file all_data\\daily_81102_2010.csv\n",
      "Adding file all_data\\daily_81102_2011.csv\n",
      "Adding file all_data\\daily_81102_2012.csv\n",
      "Adding file all_data\\daily_81102_2013.csv\n",
      "Adding file all_data\\daily_81102_2014.csv\n",
      "Adding file all_data\\daily_81102_2015.csv\n",
      "Adding file all_data\\daily_81102_2016.csv\n",
      "Adding file all_data\\daily_81102_2017.csv\n",
      "Adding file all_data\\daily_81102_2018.csv\n",
      "Adding file all_data\\daily_81102_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for pm10 for 2000-2019: (3047476, 29)\n"
     ]
    }
   ],
   "source": [
    "pm10 = combine_annual_data('pm10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_88101_2000.csv\n",
      "Adding file all_data\\daily_88101_2001.csv\n",
      "Adding file all_data\\daily_88101_2002.csv\n",
      "Adding file all_data\\daily_88101_2003.csv\n",
      "Adding file all_data\\daily_88101_2004.csv\n",
      "Adding file all_data\\daily_88101_2005.csv\n",
      "Adding file all_data\\daily_88101_2006.csv\n",
      "Adding file all_data\\daily_88101_2007.csv\n",
      "Adding file all_data\\daily_88101_2008.csv\n",
      "Adding file all_data\\daily_88101_2009.csv\n",
      "Adding file all_data\\daily_88101_2010.csv\n",
      "Adding file all_data\\daily_88101_2011.csv\n",
      "Adding file all_data\\daily_88101_2012.csv\n",
      "Adding file all_data\\daily_88101_2013.csv\n",
      "Adding file all_data\\daily_88101_2014.csv\n",
      "Adding file all_data\\daily_88101_2015.csv\n",
      "Adding file all_data\\daily_88101_2016.csv\n",
      "Adding file all_data\\daily_88101_2017.csv\n",
      "Adding file all_data\\daily_88101_2018.csv\n",
      "Adding file all_data\\daily_88101_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for pm25 for 2000-2019: (5032639, 29)\n"
     ]
    }
   ],
   "source": [
    "pm25 = combine_annual_data('pm25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_PRESS_2000.csv\n",
      "Adding file all_data\\daily_PRESS_2001.csv\n",
      "Adding file all_data\\daily_PRESS_2002.csv\n",
      "Adding file all_data\\daily_PRESS_2003.csv\n",
      "Adding file all_data\\daily_PRESS_2004.csv\n",
      "Adding file all_data\\daily_PRESS_2005.csv\n",
      "Adding file all_data\\daily_PRESS_2006.csv\n",
      "Adding file all_data\\daily_PRESS_2007.csv\n",
      "Adding file all_data\\daily_PRESS_2008.csv\n",
      "Adding file all_data\\daily_PRESS_2009.csv\n",
      "Adding file all_data\\daily_PRESS_2010.csv\n",
      "Adding file all_data\\daily_PRESS_2011.csv\n",
      "Adding file all_data\\daily_PRESS_2012.csv\n",
      "Adding file all_data\\daily_PRESS_2013.csv\n",
      "Adding file all_data\\daily_PRESS_2014.csv\n",
      "Adding file all_data\\daily_PRESS_2015.csv\n",
      "Adding file all_data\\daily_PRESS_2016.csv\n",
      "Adding file all_data\\daily_PRESS_2017.csv\n",
      "Adding file all_data\\daily_PRESS_2018.csv\n",
      "Adding file all_data\\daily_PRESS_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for pressure for 2000-2019: (1758728, 29)\n"
     ]
    }
   ],
   "source": [
    "pressure = combine_annual_data('pressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_TEMP_2000.csv\n",
      "Adding file all_data\\daily_TEMP_2001.csv\n",
      "Adding file all_data\\daily_TEMP_2002.csv\n",
      "Adding file all_data\\daily_TEMP_2003.csv\n",
      "Adding file all_data\\daily_TEMP_2004.csv\n",
      "Adding file all_data\\daily_TEMP_2005.csv\n",
      "Adding file all_data\\daily_TEMP_2006.csv\n",
      "Adding file all_data\\daily_TEMP_2007.csv\n",
      "Adding file all_data\\daily_TEMP_2008.csv\n",
      "Adding file all_data\\daily_TEMP_2009.csv\n",
      "Adding file all_data\\daily_TEMP_2010.csv\n",
      "Adding file all_data\\daily_TEMP_2011.csv\n",
      "Adding file all_data\\daily_TEMP_2012.csv\n",
      "Adding file all_data\\daily_TEMP_2013.csv\n",
      "Adding file all_data\\daily_TEMP_2014.csv\n",
      "Adding file all_data\\daily_TEMP_2015.csv\n",
      "Adding file all_data\\daily_TEMP_2016.csv\n",
      "Adding file all_data\\daily_TEMP_2017.csv\n",
      "Adding file all_data\\daily_TEMP_2018.csv\n",
      "Adding file all_data\\daily_TEMP_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for temperature for 2000-2019: (5097760, 29)\n"
     ]
    }
   ],
   "source": [
    "temperature = combine_annual_data('temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_WIND_2000.csv\n",
      "Adding file all_data\\daily_WIND_2001.csv\n",
      "Adding file all_data\\daily_WIND_2002.csv\n",
      "Adding file all_data\\daily_WIND_2003.csv\n",
      "Adding file all_data\\daily_WIND_2004.csv\n",
      "Adding file all_data\\daily_WIND_2005.csv\n",
      "Adding file all_data\\daily_WIND_2006.csv\n",
      "Adding file all_data\\daily_WIND_2007.csv\n",
      "Adding file all_data\\daily_WIND_2008.csv\n",
      "Adding file all_data\\daily_WIND_2009.csv\n",
      "Adding file all_data\\daily_WIND_2010.csv\n",
      "Adding file all_data\\daily_WIND_2011.csv\n",
      "Adding file all_data\\daily_WIND_2012.csv\n",
      "Adding file all_data\\daily_WIND_2013.csv\n",
      "Adding file all_data\\daily_WIND_2014.csv\n",
      "Adding file all_data\\daily_WIND_2015.csv\n",
      "Adding file all_data\\daily_WIND_2016.csv\n",
      "Adding file all_data\\daily_WIND_2017.csv\n",
      "Adding file all_data\\daily_WIND_2018.csv\n",
      "Adding file all_data\\daily_WIND_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for wind for 2000-2019: (7484243, 29)\n"
     ]
    }
   ],
   "source": [
    "wind = combine_annual_data('wind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file all_data\\daily_aqi_by_county_2000.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2001.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2002.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2003.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2004.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2005.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2006.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2007.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2008.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2009.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2010.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2011.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2012.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2013.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2014.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2015.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2016.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2017.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2018.csv\n",
      "Adding file all_data\\daily_aqi_by_county_2019.csv\n",
      "Combining files...\n",
      "Done! \n",
      "Shape of dataframe for aqi for 2000-2019: (6352663, 10)\n"
     ]
    }
   ],
   "source": [
    "aqi = combine_annual_data('aqi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "pollutants = ['co', 'no2', 'o3', 'so2', 'pm10', 'pm25']\n",
    "measures = ['pressure', 'temperature', 'wind']\n",
    "target = aqi\n",
    "dataframes = [co, no2, o3, so2, pm10, pm25, pressure, temperature, wind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of dataframe shapes\n",
      "(4976812, 29)\n",
      "(2829046, 29)\n",
      "(7281203, 29)\n",
      "(6874455, 29)\n",
      "(3047476, 29)\n",
      "(5032639, 29)\n",
      "(1758728, 29)\n",
      "(5097760, 29)\n",
      "(7484243, 29)\n",
      "(6352663, 10)\n",
      "There are 50735025 rows altogether in these dataframes.\n"
     ]
    }
   ],
   "source": [
    "#Total number of rows in all data\n",
    "total = 0\n",
    "print('List of dataframe shapes')\n",
    "for df in dataframes:\n",
    "    print(df.shape)\n",
    "    total += df.shape[0]\n",
    "total += target.shape[0]\n",
    "print(target.shape)\n",
    "print(f'There are {total} rows altogether in these dataframes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have combined all annual files into one dataframe for each measure. The dataframes are co, no2, o3, so2, pm10, pm25, pressure, temperature, wind, and aqi. Each dataframe consists of 20 years of daily measurements across the country for the given measure. All together there are over 50 million rows of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check For Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nulls(measure, as_percent=False):\n",
    "    \"\"\"\n",
    "    Input \n",
    "    measure\n",
    "    as_percent boolean\n",
    "    \"\"\"\n",
    "    if as_percent==True:\n",
    "        return measure.isna().sum()/len(measure)\n",
    "    else:\n",
    "        return measure.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4976812, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000\n",
       "County Code            0.000000\n",
       "Site Num               0.000000\n",
       "Parameter Code         0.000000\n",
       "POC                    0.000000\n",
       "Latitude               0.000000\n",
       "Longitude              0.000000\n",
       "Datum                  0.000000\n",
       "Parameter Name         0.000000\n",
       "Sample Duration        0.000000\n",
       "Pollutant Standard     0.000000\n",
       "Date Local             0.000000\n",
       "Units of Measure       0.000000\n",
       "Event Type             0.000000\n",
       "Observation Count      0.000000\n",
       "Observation Percent    0.000000\n",
       "Arithmetic Mean        0.000000\n",
       "1st Max Value          0.000000\n",
       "1st Max Hour           0.000000\n",
       "AQI                    0.499930\n",
       "Method Code            0.500070\n",
       "Method Name            0.000000\n",
       "Local Site Name        0.128874\n",
       "Address                0.000000\n",
       "State Name             0.000000\n",
       "County Name            0.000000\n",
       "City Name              0.000000\n",
       "CBSA Name              0.029996\n",
       "Date of Last Change    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2829046, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000\n",
       "County Code            0.000000\n",
       "Site Num               0.000000\n",
       "Parameter Code         0.000000\n",
       "POC                    0.000000\n",
       "Latitude               0.000000\n",
       "Longitude              0.000000\n",
       "Datum                  0.000000\n",
       "Parameter Name         0.000000\n",
       "Sample Duration        0.000000\n",
       "Pollutant Standard     0.000000\n",
       "Date Local             0.000000\n",
       "Units of Measure       0.000000\n",
       "Event Type             0.000000\n",
       "Observation Count      0.000000\n",
       "Observation Percent    0.000000\n",
       "Arithmetic Mean        0.000000\n",
       "1st Max Value          0.000000\n",
       "1st Max Hour           0.000000\n",
       "AQI                    0.000000\n",
       "Method Code            0.000000\n",
       "Method Name            0.000000\n",
       "Local Site Name        0.067927\n",
       "Address                0.000000\n",
       "State Name             0.000000\n",
       "County Name            0.000000\n",
       "City Name              0.000000\n",
       "CBSA Name              0.068083\n",
       "Date of Last Change    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7281203, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000e+00\n",
       "County Code            0.000000e+00\n",
       "Site Num               0.000000e+00\n",
       "Parameter Code         0.000000e+00\n",
       "POC                    0.000000e+00\n",
       "Latitude               0.000000e+00\n",
       "Longitude              0.000000e+00\n",
       "Datum                  0.000000e+00\n",
       "Parameter Name         0.000000e+00\n",
       "Sample Duration        0.000000e+00\n",
       "Pollutant Standard     0.000000e+00\n",
       "Date Local             0.000000e+00\n",
       "Units of Measure       0.000000e+00\n",
       "Event Type             0.000000e+00\n",
       "Observation Count      0.000000e+00\n",
       "Observation Percent    0.000000e+00\n",
       "Arithmetic Mean        0.000000e+00\n",
       "1st Max Value          0.000000e+00\n",
       "1st Max Hour           0.000000e+00\n",
       "AQI                    8.240397e-07\n",
       "Method Code            1.000000e+00\n",
       "Method Name            0.000000e+00\n",
       "Local Site Name        5.452945e-02\n",
       "Address                0.000000e+00\n",
       "State Name             0.000000e+00\n",
       "County Name            0.000000e+00\n",
       "City Name              0.000000e+00\n",
       "CBSA Name              9.835751e-02\n",
       "Date of Last Change    0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6874455, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000\n",
       "County Code            0.000000\n",
       "Site Num               0.000000\n",
       "Parameter Code         0.000000\n",
       "POC                    0.000000\n",
       "Latitude               0.000000\n",
       "Longitude              0.000000\n",
       "Datum                  0.000000\n",
       "Parameter Name         0.000000\n",
       "Sample Duration        0.000000\n",
       "Pollutant Standard     0.000000\n",
       "Date Local             0.000000\n",
       "Units of Measure       0.000000\n",
       "Event Type             0.000000\n",
       "Observation Count      0.000000\n",
       "Observation Percent    0.000000\n",
       "Arithmetic Mean        0.000000\n",
       "1st Max Value          0.000000\n",
       "1st Max Hour           0.000000\n",
       "AQI                    0.499787\n",
       "Method Code            0.499787\n",
       "Method Name            0.000000\n",
       "Local Site Name        0.153406\n",
       "Address                0.000000\n",
       "State Name             0.000000\n",
       "County Name            0.000000\n",
       "City Name              0.000000\n",
       "CBSA Name              0.095256\n",
       "Date of Last Change    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3047476, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000\n",
       "County Code            0.000000\n",
       "Site Num               0.000000\n",
       "Parameter Code         0.000000\n",
       "POC                    0.000000\n",
       "Latitude               0.000000\n",
       "Longitude              0.000000\n",
       "Datum                  0.000000\n",
       "Parameter Name         0.000000\n",
       "Sample Duration        0.000000\n",
       "Pollutant Standard     0.000000\n",
       "Date Local             0.000000\n",
       "Units of Measure       0.000000\n",
       "Event Type             0.000000\n",
       "Observation Count      0.000000\n",
       "Observation Percent    0.000000\n",
       "Arithmetic Mean        0.000000\n",
       "1st Max Value          0.000000\n",
       "1st Max Hour           0.000000\n",
       "AQI                    0.000000\n",
       "Method Code            0.540743\n",
       "Method Name            0.000000\n",
       "Local Site Name        0.099312\n",
       "Address                0.000000\n",
       "State Name             0.000000\n",
       "County Name            0.000000\n",
       "City Name              0.000000\n",
       "CBSA Name              0.101266\n",
       "Date of Last Change    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5032639, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000\n",
       "County Code            0.000000\n",
       "Site Num               0.000000\n",
       "Parameter Code         0.000000\n",
       "POC                    0.000000\n",
       "Latitude               0.000000\n",
       "Longitude              0.000000\n",
       "Datum                  0.000000\n",
       "Parameter Name         0.000000\n",
       "Sample Duration        0.000000\n",
       "Pollutant Standard     0.252377\n",
       "Date Local             0.000000\n",
       "Units of Measure       0.000000\n",
       "Event Type             0.000000\n",
       "Observation Count      0.000000\n",
       "Observation Percent    0.000000\n",
       "Arithmetic Mean        0.000000\n",
       "1st Max Value          0.000000\n",
       "1st Max Hour           0.000000\n",
       "AQI                    0.252377\n",
       "Method Code            0.246239\n",
       "Method Name            0.000000\n",
       "Local Site Name        0.053393\n",
       "Address                0.000156\n",
       "State Name             0.000000\n",
       "County Name            0.000000\n",
       "City Name              0.000000\n",
       "CBSA Name              0.069690\n",
       "Date of Last Change    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1758728, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000\n",
       "County Code            0.000000\n",
       "Site Num               0.000000\n",
       "Parameter Code         0.000000\n",
       "POC                    0.000000\n",
       "Latitude               0.000000\n",
       "Longitude              0.000000\n",
       "Datum                  0.000000\n",
       "Parameter Name         0.000000\n",
       "Sample Duration        0.000000\n",
       "Pollutant Standard     1.000000\n",
       "Date Local             0.000000\n",
       "Units of Measure       0.000000\n",
       "Event Type             0.000000\n",
       "Observation Count      0.000000\n",
       "Observation Percent    0.000000\n",
       "Arithmetic Mean        0.000000\n",
       "1st Max Value          0.000000\n",
       "1st Max Hour           0.000000\n",
       "AQI                    1.000000\n",
       "Method Code            0.000000\n",
       "Method Name            0.000000\n",
       "Local Site Name        0.084798\n",
       "Address                0.000000\n",
       "State Name             0.000000\n",
       "County Name            0.000000\n",
       "City Name              0.000000\n",
       "CBSA Name              0.134576\n",
       "Date of Last Change    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5097760, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000\n",
       "County Code            0.000000\n",
       "Site Num               0.000000\n",
       "Parameter Code         0.000000\n",
       "POC                    0.000000\n",
       "Latitude               0.000000\n",
       "Longitude              0.000000\n",
       "Datum                  0.000000\n",
       "Parameter Name         0.000000\n",
       "Sample Duration        0.000000\n",
       "Pollutant Standard     1.000000\n",
       "Date Local             0.000000\n",
       "Units of Measure       0.000000\n",
       "Event Type             0.000000\n",
       "Observation Count      0.000000\n",
       "Observation Percent    0.000000\n",
       "Arithmetic Mean        0.000000\n",
       "1st Max Value          0.000000\n",
       "1st Max Hour           0.000000\n",
       "AQI                    1.000000\n",
       "Method Code            0.000000\n",
       "Method Name            0.000000\n",
       "Local Site Name        0.073660\n",
       "Address                0.000000\n",
       "State Name             0.000000\n",
       "County Name            0.000000\n",
       "City Name              0.000000\n",
       "CBSA Name              0.131998\n",
       "Date of Last Change    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7484243, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Code             0.000000\n",
       "County Code            0.000000\n",
       "Site Num               0.000000\n",
       "Parameter Code         0.000000\n",
       "POC                    0.000000\n",
       "Latitude               0.000000\n",
       "Longitude              0.000000\n",
       "Datum                  0.000000\n",
       "Parameter Name         0.000000\n",
       "Sample Duration        0.000000\n",
       "Pollutant Standard     1.000000\n",
       "Date Local             0.000000\n",
       "Units of Measure       0.000000\n",
       "Event Type             0.000000\n",
       "Observation Count      0.000000\n",
       "Observation Percent    0.000000\n",
       "Arithmetic Mean        0.000000\n",
       "1st Max Value          0.000000\n",
       "1st Max Hour           0.000000\n",
       "AQI                    1.000000\n",
       "Method Code            0.000000\n",
       "Method Name            0.000000\n",
       "Local Site Name        0.043518\n",
       "Address                0.000000\n",
       "State Name             0.000000\n",
       "County Name            0.000000\n",
       "City Name              0.000000\n",
       "CBSA Name              0.100513\n",
       "Date of Last Change    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6352663, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State Name                   0.0\n",
       "county Name                  0.0\n",
       "State Code                   0.0\n",
       "County Code                  0.0\n",
       "Date                         0.0\n",
       "AQI                          0.0\n",
       "Category                     0.0\n",
       "Defining Parameter           0.0\n",
       "Defining Site                0.0\n",
       "Number of Sites Reporting    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframes = [co, no2, o3, so2, pm10, pm25, pressure, temperature, wind, aqi]\n",
    "num = 0\n",
    "for df in dataframes: \n",
    "    print(num)\n",
    "    display(df.shape)\n",
    "    display(check_nulls(df, as_percent=True))\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have now combined the daily data for each of the 6 pollutants, 3 meterological measures and AQI for the years 2000 through 2019. The next task is to combine these 10 dataframes into 1 dateframe for modeling. I need to first standardize the column names and pick the features I want to include. Then I will need to check data types and handle null values and placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Code</th>\n",
       "      <th>County Code</th>\n",
       "      <th>Site Num</th>\n",
       "      <th>Parameter Code</th>\n",
       "      <th>POC</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Parameter Name</th>\n",
       "      <th>Sample Duration</th>\n",
       "      <th>Pollutant Standard</th>\n",
       "      <th>Date Local</th>\n",
       "      <th>Units of Measure</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>Observation Count</th>\n",
       "      <th>Observation Percent</th>\n",
       "      <th>Arithmetic Mean</th>\n",
       "      <th>1st Max Value</th>\n",
       "      <th>1st Max Hour</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Method Code</th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Local Site Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>State Name</th>\n",
       "      <th>County Name</th>\n",
       "      <th>City Name</th>\n",
       "      <th>CBSA Name</th>\n",
       "      <th>Date of Last Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>42101</td>\n",
       "      <td>1</td>\n",
       "      <td>33.529444</td>\n",
       "      <td>-86.850278</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Carbon monoxide</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>CO 1-hour 1971</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>INSTRUMENTAL - NONDISPERSIVE INFRARED PHOTOMETRY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EAST THOMAS, FINLEY, 841 FINLEY AVE. BP.</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Birmingham-Hoover, AL</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Code  County Code  Site Num  Parameter Code  POC   Latitude  \\\n",
       "0           1           73        28           42101    1  33.529444   \n",
       "\n",
       "   Longitude  Datum   Parameter Name Sample Duration Pollutant Standard  \\\n",
       "0 -86.850278  WGS84  Carbon monoxide          1 HOUR     CO 1-hour 1971   \n",
       "\n",
       "   Date Local   Units of Measure Event Type  Observation Count  \\\n",
       "0  2000-01-01  Parts per million       None                 24   \n",
       "\n",
       "   Observation Percent  Arithmetic Mean  1st Max Value  1st Max Hour  AQI  \\\n",
       "0                100.0         0.970833            1.4             3  NaN   \n",
       "\n",
       "   Method Code                                       Method Name  \\\n",
       "0         88.0  INSTRUMENTAL - NONDISPERSIVE INFRARED PHOTOMETRY   \n",
       "\n",
       "  Local Site Name                                   Address State Name  \\\n",
       "0             NaN  EAST THOMAS, FINLEY, 841 FINLEY AVE. BP.    Alabama   \n",
       "\n",
       "  County Name   City Name              CBSA Name Date of Last Change  \n",
       "0   Jefferson  Birmingham  Birmingham-Hoover, AL          2016-04-15  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC',\n",
       "       'Latitude', 'Longitude', 'Datum', 'Parameter Name', 'Sample Duration',\n",
       "       'Pollutant Standard', 'Date Local', 'Units of Measure', 'Event Type',\n",
       "       'Observation Count', 'Observation Percent', 'Arithmetic Mean',\n",
       "       '1st Max Value', '1st Max Hour', 'AQI', 'Method Code', 'Method Name',\n",
       "       'Local Site Name', 'Address', 'State Name', 'County Name', 'City Name',\n",
       "       'CBSA Name', 'Date of Last Change'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4976812 entries, 0 to 4976811\n",
      "Data columns (total 29 columns):\n",
      "State Code             int64\n",
      "County Code            int64\n",
      "Site Num               int64\n",
      "Parameter Code         int64\n",
      "POC                    int64\n",
      "Latitude               float64\n",
      "Longitude              float64\n",
      "Datum                  object\n",
      "Parameter Name         object\n",
      "Sample Duration        object\n",
      "Pollutant Standard     object\n",
      "Date Local             object\n",
      "Units of Measure       object\n",
      "Event Type             object\n",
      "Observation Count      int64\n",
      "Observation Percent    float64\n",
      "Arithmetic Mean        float64\n",
      "1st Max Value          float64\n",
      "1st Max Hour           int64\n",
      "AQI                    float64\n",
      "Method Code            float64\n",
      "Method Name            object\n",
      "Local Site Name        object\n",
      "Address                object\n",
      "State Name             object\n",
      "County Name            object\n",
      "City Name              object\n",
      "CBSA Name              object\n",
      "Date of Last Change    object\n",
      "dtypes: float64(7), int64(7), object(15)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "co.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6352663 entries, 0 to 6352662\n",
      "Data columns (total 10 columns):\n",
      "State Name                   object\n",
      "county Name                  object\n",
      "State Code                   object\n",
      "County Code                  int64\n",
      "Date                         object\n",
      "AQI                          int64\n",
      "Category                     object\n",
      "Defining Parameter           object\n",
      "Defining Site                object\n",
      "Number of Sites Reporting    int64\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 484.7+ MB\n"
     ]
    }
   ],
   "source": [
    "aqi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert date_local to datetime format\n",
    "dataframes = [co, no2, o3, so2, pm10, pm25, pressure, temperature, wind]\n",
    "for df in dataframes:\n",
    "    df['Date Local'] = pd.to_datetime(df['Date Local'], format='%Y-%m-%d')\n",
    "aqi['Date'] = pd.to_datetime(aqi['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6352663 entries, 0 to 6352662\n",
      "Data columns (total 10 columns):\n",
      "State Name                   object\n",
      "county Name                  object\n",
      "State Code                   object\n",
      "County Code                  int64\n",
      "Date                         datetime64[ns]\n",
      "AQI                          int64\n",
      "Category                     object\n",
      "Defining Parameter           object\n",
      "Defining Site                object\n",
      "Number of Sites Reporting    int64\n",
      "dtypes: datetime64[ns](1), int64(3), object(6)\n",
      "memory usage: 484.7+ MB\n"
     ]
    }
   ],
   "source": [
    "aqi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4976812 entries, 0 to 4976811\n",
      "Data columns (total 29 columns):\n",
      "State Code             int64\n",
      "County Code            int64\n",
      "Site Num               int64\n",
      "Parameter Code         int64\n",
      "POC                    int64\n",
      "Latitude               float64\n",
      "Longitude              float64\n",
      "Datum                  object\n",
      "Parameter Name         object\n",
      "Sample Duration        object\n",
      "Pollutant Standard     object\n",
      "Date Local             datetime64[ns]\n",
      "Units of Measure       object\n",
      "Event Type             object\n",
      "Observation Count      int64\n",
      "Observation Percent    float64\n",
      "Arithmetic Mean        float64\n",
      "1st Max Value          float64\n",
      "1st Max Hour           int64\n",
      "AQI                    float64\n",
      "Method Code            float64\n",
      "Method Name            object\n",
      "Local Site Name        object\n",
      "Address                object\n",
      "State Name             object\n",
      "County Name            object\n",
      "City Name              object\n",
      "CBSA Name              object\n",
      "Date of Last Change    object\n",
      "dtypes: datetime64[ns](1), float64(7), int64(7), object(14)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "co.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All dataframes have identical column names except for aqi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Check if columns are the same across all dataframes\n",
    "print(co.columns == no2.columns)\n",
    "print(co.columns == o3.columns)\n",
    "print(co.columns == so2.columns)\n",
    "print(co.columns == pm10.columns)\n",
    "print(co.columns == pm25.columns)\n",
    "print(co.columns == pressure.columns)\n",
    "print(co.columns == temperature.columns)\n",
    "print(co.columns == wind.columns)\n",
    "print(co.shape == aqi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC',\n",
       "       'Latitude', 'Longitude', 'Datum', 'Parameter Name', 'Sample Duration',\n",
       "       'Pollutant Standard', 'Date Local', 'Units of Measure', 'Event Type',\n",
       "       'Observation Count', 'Observation Percent', 'Arithmetic Mean',\n",
       "       '1st Max Value', '1st Max Hour', 'AQI', 'Method Code', 'Method Name',\n",
       "       'Local Site Name', 'Address', 'State Name', 'County Name', 'City Name',\n",
       "       'CBSA Name', 'Date of Last Change'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize column names\n",
    "for dataframe in dataframes:\n",
    "    dataframe.columns = dataframe.columns.str.replace(' ', '_')\n",
    "    dataframe.columns = dataframe.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi.columns = aqi.columns.str.replace(' ', '_')\n",
    "aqi.columns = aqi.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state_code', 'county_code', 'site_num', 'parameter_code', 'poc',\n",
       "       'latitude', 'longitude', 'datum', 'parameter_name', 'sample_duration',\n",
       "       'pollutant_standard', 'date_local', 'units_of_measure', 'event_type',\n",
       "       'observation_count', 'observation_percent', 'arithmetic_mean',\n",
       "       '1st_max_value', '1st_max_hour', 'aqi', 'method_code', 'method_name',\n",
       "       'local_site_name', 'address', 'state_name', 'county_name', 'city_name',\n",
       "       'cbsa_name', 'date_of_last_change'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n",
       "       'category', 'defining_parameter', 'defining_site',\n",
       "       'number_of_sites_reporting'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>date</th>\n",
       "      <th>aqi</th>\n",
       "      <th>category</th>\n",
       "      <th>defining_parameter</th>\n",
       "      <th>defining_site</th>\n",
       "      <th>number_of_sites_reporting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-16</td>\n",
       "      <td>25</td>\n",
       "      <td>Good</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01-003-0010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_name county_name state_code  county_code       date  aqi category  \\\n",
       "0    Alabama     Baldwin         01            3 2000-01-16   25     Good   \n",
       "\n",
       "  defining_parameter defining_site  number_of_sites_reporting  \n",
       "0              PM2.5   01-003-0010                          1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>date_local</th>\n",
       "      <th>aqi</th>\n",
       "      <th>category</th>\n",
       "      <th>defining_parameter</th>\n",
       "      <th>defining_site</th>\n",
       "      <th>number_of_sites_reporting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-16</td>\n",
       "      <td>25</td>\n",
       "      <td>Good</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01-003-0010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_name county_name state_code  county_code date_local  aqi category  \\\n",
       "0    Alabama     Baldwin         01            3 2000-01-16   25     Good   \n",
       "\n",
       "  defining_parameter defining_site  number_of_sites_reporting  \n",
       "0              PM2.5   01-003-0010                          1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi.rename(columns={'date': 'date_local'}, inplace=True)\n",
    "aqi.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>42101</td>\n",
       "      <td>1</td>\n",
       "      <td>33.529444</td>\n",
       "      <td>-86.850278</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Carbon monoxide</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>CO 1-hour 1971</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>INSTRUMENTAL - NONDISPERSIVE INFRARED PHOTOMETRY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EAST THOMAS, FINLEY, 841 FINLEY AVE. BP.</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Birmingham-Hoover, AL</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code  county_code  site_num  parameter_code  poc   latitude  \\\n",
       "0           1           73        28           42101    1  33.529444   \n",
       "\n",
       "   longitude  datum   parameter_name sample_duration pollutant_standard  \\\n",
       "0 -86.850278  WGS84  Carbon monoxide          1 HOUR     CO 1-hour 1971   \n",
       "\n",
       "  date_local   units_of_measure event_type  observation_count  \\\n",
       "0 2000-01-01  Parts per million       None                 24   \n",
       "\n",
       "   observation_percent  arithmetic_mean  1st_max_value  1st_max_hour  aqi  \\\n",
       "0                100.0         0.970833            1.4             3  NaN   \n",
       "\n",
       "   method_code                                       method_name  \\\n",
       "0         88.0  INSTRUMENTAL - NONDISPERSIVE INFRARED PHOTOMETRY   \n",
       "\n",
       "  local_site_name                                   address state_name  \\\n",
       "0             NaN  EAST THOMAS, FINLEY, 841 FINLEY AVE. BP.    Alabama   \n",
       "\n",
       "  county_name   city_name              cbsa_name date_of_last_change  \n",
       "0   Jefferson  Birmingham  Birmingham-Hoover, AL          2016-04-15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>42602</td>\n",
       "      <td>1</td>\n",
       "      <td>33.317142</td>\n",
       "      <td>-86.825754</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Nitrogen dioxide (NO2)</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>NO2 1-hour</td>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.875</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>90</td>\n",
       "      <td>INSTRUMENTAL - GAS-PHASE CHEMILUMINESCENCE</td>\n",
       "      <td>HELENA</td>\n",
       "      <td>HELENA, BEARDEN FARM</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Shelby</td>\n",
       "      <td>Helena</td>\n",
       "      <td>Birmingham-Hoover, AL</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  county_code  site_num  parameter_code  poc   latitude  \\\n",
       "0          1          117         4           42602    1  33.317142   \n",
       "\n",
       "   longitude  datum          parameter_name sample_duration  \\\n",
       "0 -86.825754  NAD83  Nitrogen dioxide (NO2)          1 HOUR   \n",
       "\n",
       "  pollutant_standard date_local   units_of_measure event_type  \\\n",
       "0         NO2 1-hour 2000-03-01  Parts per billion       None   \n",
       "\n",
       "   observation_count  observation_percent  arithmetic_mean  1st_max_value  \\\n",
       "0                 24                100.0            7.875           20.0   \n",
       "\n",
       "   1st_max_hour  aqi  method_code                                 method_name  \\\n",
       "0             5   19           90  INSTRUMENTAL - GAS-PHASE CHEMILUMINESCENCE   \n",
       "\n",
       "  local_site_name               address state_name county_name city_name  \\\n",
       "0          HELENA  HELENA, BEARDEN FARM    Alabama      Shelby    Helena   \n",
       "\n",
       "               cbsa_name date_of_last_change  \n",
       "0  Birmingham-Hoover, AL          2013-06-11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>23</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  county_code  site_num  parameter_code  poc   latitude  \\\n",
       "0          1            3        10           44201    1  30.497478   \n",
       "\n",
       "   longitude  datum parameter_name          sample_duration  \\\n",
       "0 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "\n",
       "  pollutant_standard date_local   units_of_measure event_type  \\\n",
       "0  Ozone 8-hour 2015 2000-02-29  Parts per million       None   \n",
       "\n",
       "   observation_count  observation_percent  arithmetic_mean  1st_max_value  \\\n",
       "0                  1                  6.0            0.023          0.023   \n",
       "\n",
       "   1st_max_hour   aqi  method_code method_name    local_site_name  \\\n",
       "0            23  21.0          NaN          -   FAIRHOPE, Alabama   \n",
       "\n",
       "                                             address state_name county_name  \\\n",
       "0  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "\n",
       "  city_name                  cbsa_name date_of_last_change  \n",
       "0  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>44</td>\n",
       "      <td>42401</td>\n",
       "      <td>1</td>\n",
       "      <td>34.690647</td>\n",
       "      <td>-87.821422</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Sulfur dioxide</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>SO2 1-hour 2010</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.625</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>INSTRUMENTAL - PULSED FLUORESCENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TVA COLBERT 14___3.98 MI SE COLBERT FP</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Colbert</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>Florence-Muscle Shoals, AL</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  county_code  site_num  parameter_code  poc   latitude  \\\n",
       "0          1           33        44           42401    1  34.690647   \n",
       "\n",
       "   longitude  datum  parameter_name sample_duration pollutant_standard  \\\n",
       "0 -87.821422  WGS84  Sulfur dioxide          1 HOUR    SO2 1-hour 2010   \n",
       "\n",
       "  date_local   units_of_measure event_type  observation_count  \\\n",
       "0 2000-01-01  Parts per billion       None                 24   \n",
       "\n",
       "   observation_percent  arithmetic_mean  1st_max_value  1st_max_hour   aqi  \\\n",
       "0                100.0            1.625            7.0             0  10.0   \n",
       "\n",
       "   method_code                        method_name local_site_name  \\\n",
       "0         20.0  INSTRUMENTAL - PULSED FLUORESCENT             NaN   \n",
       "\n",
       "                                  address state_name county_name  \\\n",
       "0  TVA COLBERT 14___3.98 MI SE COLBERT FP    Alabama     Colbert   \n",
       "\n",
       "       city_name                   cbsa_name date_of_last_change  \n",
       "0  Not in a city  Florence-Muscle Shoals, AL          2013-06-11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1002</td>\n",
       "      <td>81102</td>\n",
       "      <td>1</td>\n",
       "      <td>34.456199</td>\n",
       "      <td>-85.707189</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM10 Total 0-10um STP</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>PM10 24-hour 2006</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Micrograms/cubic meter (25 C)</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63.0</td>\n",
       "      <td>HI-VOL SA/GMW-1200 - GRAVIMETRIC</td>\n",
       "      <td>FT.PAYNE (CLOSED)</td>\n",
       "      <td>1500 WILLIAMS AVE. N.E.</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>DeKalb</td>\n",
       "      <td>Fort Payne</td>\n",
       "      <td>Fort Payne, AL</td>\n",
       "      <td>2019-09-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code  county_code  site_num  parameter_code  poc   latitude  \\\n",
       "0           1           49      1002           81102    1  34.456199   \n",
       "\n",
       "   longitude  datum         parameter_name sample_duration pollutant_standard  \\\n",
       "0 -85.707189  WGS84  PM10 Total 0-10um STP         24 HOUR  PM10 24-hour 2006   \n",
       "\n",
       "  date_local               units_of_measure event_type  observation_count  \\\n",
       "0 2000-01-01  Micrograms/cubic meter (25 C)       None                  1   \n",
       "\n",
       "   observation_percent  arithmetic_mean  1st_max_value  1st_max_hour  aqi  \\\n",
       "0                100.0             13.0           13.0             0   12   \n",
       "\n",
       "   method_code                       method_name    local_site_name  \\\n",
       "0         63.0  HI-VOL SA/GMW-1200 - GRAVIMETRIC  FT.PAYNE (CLOSED)   \n",
       "\n",
       "                   address state_name county_name   city_name       cbsa_name  \\\n",
       "0  1500 WILLIAMS AVE. N.E.    Alabama      DeKalb  Fort Payne  Fort Payne, AL   \n",
       "\n",
       "  date_of_last_change  \n",
       "0          2019-09-09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>88101</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>PM25 24-hour 2012</td>\n",
       "      <td>2000-01-16</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Andersen RAAS2.5-300 PM2.5 SEQ w/WINS - GRAVIM...</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2015-04-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  county_code  site_num  parameter_code  poc   latitude  \\\n",
       "0          1            3        10           88101    1  30.497478   \n",
       "\n",
       "   longitude  datum            parameter_name sample_duration  \\\n",
       "0 -87.880258  NAD83  PM2.5 - Local Conditions         24 HOUR   \n",
       "\n",
       "  pollutant_standard date_local             units_of_measure event_type  \\\n",
       "0  PM25 24-hour 2012 2000-01-16  Micrograms/cubic meter (LC)       None   \n",
       "\n",
       "   observation_count  observation_percent  arithmetic_mean  1st_max_value  \\\n",
       "0                  1                100.0              5.9            5.9   \n",
       "\n",
       "   1st_max_hour   aqi  method_code  \\\n",
       "0             0  25.0        120.0   \n",
       "\n",
       "                                         method_name    local_site_name  \\\n",
       "0  Andersen RAAS2.5-300 PM2.5 SEQ w/WINS - GRAVIM...  FAIRHOPE, Alabama   \n",
       "\n",
       "                                             address state_name county_name  \\\n",
       "0  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "\n",
       "  city_name                  cbsa_name date_of_last_change  \n",
       "0  Fairhope  Daphne-Fairhope-Foley, AL          2015-04-02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>64101</td>\n",
       "      <td>1</td>\n",
       "      <td>39.757371</td>\n",
       "      <td>-121.843286</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Barometric pressure</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Millibars</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>INSTRUMENTAL - BAROMETRIC SENSOR</td>\n",
       "      <td>Chico-Manzanita Ave.</td>\n",
       "      <td>468 MANZANITA AVE, CHICO</td>\n",
       "      <td>California</td>\n",
       "      <td>Butte</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>Chico, CA</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code  county_code  site_num  parameter_code  poc   latitude  \\\n",
       "0           6            7         2           64101    1  39.757371   \n",
       "\n",
       "    longitude  datum       parameter_name sample_duration  pollutant_standard  \\\n",
       "0 -121.843286  WGS84  Barometric pressure          1 HOUR                 NaN   \n",
       "\n",
       "  date_local units_of_measure event_type  observation_count  \\\n",
       "0 2000-01-01        Millibars       None                 24   \n",
       "\n",
       "   observation_percent  arithmetic_mean  1st_max_value  1st_max_hour  aqi  \\\n",
       "0                100.0           1007.9         1009.2             9  NaN   \n",
       "\n",
       "   method_code                       method_name       local_site_name  \\\n",
       "0           14  INSTRUMENTAL - BAROMETRIC SENSOR  Chico-Manzanita Ave.   \n",
       "\n",
       "                    address  state_name county_name      city_name  cbsa_name  \\\n",
       "0  468 MANZANITA AVE, CHICO  California       Butte  Not in a city  Chico, CA   \n",
       "\n",
       "  date_of_last_change  \n",
       "0          2013-06-11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>62101</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7232</td>\n",
       "      <td>-148.9676</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Outdoor Temperature</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Degrees Fahrenheit</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-25.541667</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>INSTRUMENTAL - ELEC. OR MACH. AVG. LEVEL 1</td>\n",
       "      <td>Denali NP &amp; PRES - Headquarters</td>\n",
       "      <td>DENALI NATIONAL PARK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Denali</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code  county_code  site_num  parameter_code  poc  latitude  \\\n",
       "0           2           68         3           62101    1   63.7232   \n",
       "\n",
       "   longitude  datum       parameter_name sample_duration  pollutant_standard  \\\n",
       "0  -148.9676  WGS84  Outdoor Temperature          1 HOUR                 NaN   \n",
       "\n",
       "  date_local    units_of_measure event_type  observation_count  \\\n",
       "0 2000-01-01  Degrees Fahrenheit       None                 24   \n",
       "\n",
       "   observation_percent  arithmetic_mean  1st_max_value  1st_max_hour  aqi  \\\n",
       "0                100.0       -25.541667          -18.0            23  NaN   \n",
       "\n",
       "   method_code                                 method_name  \\\n",
       "0           41  INSTRUMENTAL - ELEC. OR MACH. AVG. LEVEL 1   \n",
       "\n",
       "                   local_site_name               address state_name  \\\n",
       "0  Denali NP & PRES - Headquarters  DENALI NATIONAL PARK     Alaska   \n",
       "\n",
       "  county_name      city_name cbsa_name date_of_last_change  \n",
       "0     Denali   Not in a city       NaN          2013-06-11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>61103</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7232</td>\n",
       "      <td>-148.9676</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>Wind Speed - Resultant</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-16</td>\n",
       "      <td>Knots</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>3.3</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>INSTRUMENTAL - VECTOR SUMMATION</td>\n",
       "      <td>Denali NP &amp; PRES - Headquarters</td>\n",
       "      <td>DENALI NATIONAL PARK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Denali</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code  county_code  site_num  parameter_code  poc  latitude  \\\n",
       "0           2           68         3           61103    1   63.7232   \n",
       "\n",
       "   longitude  datum          parameter_name sample_duration  \\\n",
       "0  -148.9676  WGS84  Wind Speed - Resultant          1 HOUR   \n",
       "\n",
       "   pollutant_standard date_local units_of_measure event_type  \\\n",
       "0                 NaN 2000-01-16            Knots       None   \n",
       "\n",
       "   observation_count  observation_percent  arithmetic_mean  1st_max_value  \\\n",
       "0                  7                 29.0         2.271429            3.3   \n",
       "\n",
       "   1st_max_hour  aqi  method_code                      method_name  \\\n",
       "0            21  NaN           20  INSTRUMENTAL - VECTOR SUMMATION   \n",
       "\n",
       "                   local_site_name               address state_name  \\\n",
       "0  Denali NP & PRES - Headquarters  DENALI NATIONAL PARK     Alaska   \n",
       "\n",
       "  county_name      city_name cbsa_name date_of_last_change  \n",
       "0     Denali   Not in a city       NaN          2016-04-29  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check\n",
    "for dataframe in dataframes:\n",
    "    display(dataframe.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All column names have now been standardized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Merge Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column for each dataframe with location and date information to use for merging dataframes\n",
    "for df in dataframes:\n",
    "    df['merge_column'] = [f'{x}-{y}-{z}' for x, y, z in zip(df['state_name'], df['county_name'], df['date_local'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi['merge_column'] = [f'{x}-{y}-{z}' for x, y, z in zip(aqi['state_name'], aqi['county_name'], aqi['date_local'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>date_local</th>\n",
       "      <th>aqi</th>\n",
       "      <th>category</th>\n",
       "      <th>defining_parameter</th>\n",
       "      <th>defining_site</th>\n",
       "      <th>number_of_sites_reporting</th>\n",
       "      <th>merge_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-16</td>\n",
       "      <td>25</td>\n",
       "      <td>Good</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01-003-0010</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama-Baldwin-2000-01-16 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_name county_name state_code  county_code date_local  aqi category  \\\n",
       "0    Alabama     Baldwin         01            3 2000-01-16   25     Good   \n",
       "\n",
       "  defining_parameter defining_site  number_of_sites_reporting  \\\n",
       "0              PM2.5   01-003-0010                          1   \n",
       "\n",
       "                          merge_column  \n",
       "0  Alabama-Baldwin-2000-01-16 00:00:00  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_standard</th>\n",
       "      <th>date_local</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>event_type</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>1st_max_value</th>\n",
       "      <th>1st_max_hour</th>\n",
       "      <th>aqi</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>address</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cbsa_name</th>\n",
       "      <th>date_of_last_change</th>\n",
       "      <th>merge_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.023</td>\n",
       "      <td>23</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-02-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>0.046</td>\n",
       "      <td>11</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-02</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.037765</td>\n",
       "      <td>0.062</td>\n",
       "      <td>11</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-03</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.034941</td>\n",
       "      <td>0.037</td>\n",
       "      <td>10</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-03 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-04</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.038</td>\n",
       "      <td>11</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-05</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>0.056</td>\n",
       "      <td>12</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-06</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>0.065</td>\n",
       "      <td>10</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-06 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-07</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.050882</td>\n",
       "      <td>0.072</td>\n",
       "      <td>10</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-08</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.043059</td>\n",
       "      <td>0.056</td>\n",
       "      <td>10</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44201</td>\n",
       "      <td>1</td>\n",
       "      <td>30.497478</td>\n",
       "      <td>-87.880258</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>Ozone 8-hour 2015</td>\n",
       "      <td>2000-03-09</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.039</td>\n",
       "      <td>9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>FAIRHOPE, Alabama</td>\n",
       "      <td>FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>Alabama-Baldwin-2000-03-09 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  county_code  site_num  parameter_code  poc   latitude  \\\n",
       "0          1            3        10           44201    1  30.497478   \n",
       "1          1            3        10           44201    1  30.497478   \n",
       "2          1            3        10           44201    1  30.497478   \n",
       "3          1            3        10           44201    1  30.497478   \n",
       "4          1            3        10           44201    1  30.497478   \n",
       "5          1            3        10           44201    1  30.497478   \n",
       "6          1            3        10           44201    1  30.497478   \n",
       "7          1            3        10           44201    1  30.497478   \n",
       "8          1            3        10           44201    1  30.497478   \n",
       "9          1            3        10           44201    1  30.497478   \n",
       "\n",
       "   longitude  datum parameter_name          sample_duration  \\\n",
       "0 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "1 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "2 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "3 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "4 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "5 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "6 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "7 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "8 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "9 -87.880258  NAD83          Ozone  8-HR RUN AVG BEGIN HOUR   \n",
       "\n",
       "  pollutant_standard date_local   units_of_measure event_type  \\\n",
       "0  Ozone 8-hour 2015 2000-02-29  Parts per million       None   \n",
       "1  Ozone 8-hour 2015 2000-03-01  Parts per million       None   \n",
       "2  Ozone 8-hour 2015 2000-03-02  Parts per million       None   \n",
       "3  Ozone 8-hour 2015 2000-03-03  Parts per million       None   \n",
       "4  Ozone 8-hour 2015 2000-03-04  Parts per million       None   \n",
       "5  Ozone 8-hour 2015 2000-03-05  Parts per million       None   \n",
       "6  Ozone 8-hour 2015 2000-03-06  Parts per million       None   \n",
       "7  Ozone 8-hour 2015 2000-03-07  Parts per million       None   \n",
       "8  Ozone 8-hour 2015 2000-03-08  Parts per million       None   \n",
       "9  Ozone 8-hour 2015 2000-03-09  Parts per million       None   \n",
       "\n",
       "   observation_count  observation_percent  arithmetic_mean  1st_max_value  \\\n",
       "0                  1                  6.0         0.023000          0.023   \n",
       "1                 17                100.0         0.036471          0.046   \n",
       "2                 17                100.0         0.037765          0.062   \n",
       "3                 17                100.0         0.034941          0.037   \n",
       "4                 17                100.0         0.028882          0.038   \n",
       "5                 17                100.0         0.036471          0.056   \n",
       "6                 17                100.0         0.038941          0.065   \n",
       "7                 17                100.0         0.050882          0.072   \n",
       "8                 17                100.0         0.043059          0.056   \n",
       "9                 17                100.0         0.033000          0.039   \n",
       "\n",
       "   1st_max_hour    aqi  method_code method_name    local_site_name  \\\n",
       "0            23   21.0          NaN          -   FAIRHOPE, Alabama   \n",
       "1            11   43.0          NaN          -   FAIRHOPE, Alabama   \n",
       "2            11   74.0          NaN          -   FAIRHOPE, Alabama   \n",
       "3            10   34.0          NaN          -   FAIRHOPE, Alabama   \n",
       "4            11   35.0          NaN          -   FAIRHOPE, Alabama   \n",
       "5            12   54.0          NaN          -   FAIRHOPE, Alabama   \n",
       "6            10   84.0          NaN          -   FAIRHOPE, Alabama   \n",
       "7            10  105.0          NaN          -   FAIRHOPE, Alabama   \n",
       "8            10   54.0          NaN          -   FAIRHOPE, Alabama   \n",
       "9             9   36.0          NaN          -   FAIRHOPE, Alabama   \n",
       "\n",
       "                                             address state_name county_name  \\\n",
       "0  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "1  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "2  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "3  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "4  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "5  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "6  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "7  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "8  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "9  FAIRHOPE HIGH SCHOOL, 1 PIRATE DRIVE, FAIRHOPE...    Alabama     Baldwin   \n",
       "\n",
       "  city_name                  cbsa_name date_of_last_change  \\\n",
       "0  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "1  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "2  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "3  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "4  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "5  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "6  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "7  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "8  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "9  Fairhope  Daphne-Fairhope-Foley, AL          2018-07-18   \n",
       "\n",
       "                          merge_column  \n",
       "0  Alabama-Baldwin-2000-02-29 00:00:00  \n",
       "1  Alabama-Baldwin-2000-03-01 00:00:00  \n",
       "2  Alabama-Baldwin-2000-03-02 00:00:00  \n",
       "3  Alabama-Baldwin-2000-03-03 00:00:00  \n",
       "4  Alabama-Baldwin-2000-03-04 00:00:00  \n",
       "5  Alabama-Baldwin-2000-03-05 00:00:00  \n",
       "6  Alabama-Baldwin-2000-03-06 00:00:00  \n",
       "7  Alabama-Baldwin-2000-03-07 00:00:00  \n",
       "8  Alabama-Baldwin-2000-03-08 00:00:00  \n",
       "9  Alabama-Baldwin-2000-03-09 00:00:00  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove spaces from all entries in merge_column\n",
    "for df in dataframes:\n",
    "    df['merge_column'] = df['merge_column'].apply(lambda x: x.replace(' ', '',))\n",
    "aqi['merge_column'] = aqi['merge_column'].apply(lambda x: x.replace(' ', '',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter observation_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure I am using quality data, I will drop any rows where the observation percent is less than 75% using my `filter_observation_percent` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_observation_percent(df, threshold=75):\n",
    "    df = df.loc[df['observation_percent'] >= threshold]\n",
    "    print(f'New value counts: {df.observation_percent.value_counts()}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0    3823344\n",
       "96.0      708344\n",
       "92.0      184931\n",
       "88.0       60838\n",
       "75.0       40600\n",
       "83.0       26688\n",
       "79.0       21758\n",
       "71.0       21153\n",
       "67.0       14439\n",
       "63.0       11207\n",
       "58.0        8897\n",
       "54.0        7565\n",
       "50.0        7067\n",
       "46.0        6264\n",
       "42.0        5748\n",
       "38.0        5287\n",
       "33.0        4365\n",
       "29.0        3621\n",
       "8.0         3228\n",
       "25.0        3158\n",
       "21.0        2637\n",
       "17.0        2311\n",
       "13.0        1921\n",
       "4.0         1441\n",
       "Name: observation_percent, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.observation_percent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value counts: 100.0    3823344\n",
      "96.0      708344\n",
      "92.0      184931\n",
      "88.0       60838\n",
      "75.0       40600\n",
      "83.0       26688\n",
      "79.0       21758\n",
      "Name: observation_percent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "co = filter_observation_percent(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value counts: 100.0    1522978\n",
      "96.0      801798\n",
      "92.0      259490\n",
      "88.0       91131\n",
      "83.0       48704\n",
      "79.0       25317\n",
      "75.0       16345\n",
      "Name: observation_percent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no2 = filter_observation_percent(no2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value counts: 100.0    7006426\n",
      "76.0       37375\n",
      "82.0       34635\n",
      "88.0       27072\n",
      "94.0       20616\n",
      "Name: observation_percent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "o3 = filter_observation_percent(o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value counts: 100.0    4309494\n",
      "88.0     1110413\n",
      "96.0      871125\n",
      "92.0      228755\n",
      "75.0      173175\n",
      "83.0       32325\n",
      "79.0       15961\n",
      "Name: observation_percent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "so2 = filter_observation_percent(so2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value counts: 100.0    3047476\n",
      "Name: observation_percent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pm10 = filter_observation_percent(pm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0    4830845\n",
       "96.0       80910\n",
       "92.0       39185\n",
       "200.0      17510\n",
       "88.0       17059\n",
       "83.0        8043\n",
       "79.0        4683\n",
       "75.0        3171\n",
       "54.0        3142\n",
       "50.0        3072\n",
       "58.0        2962\n",
       "46.0        2957\n",
       "42.0        2742\n",
       "63.0        2650\n",
       "67.0        2502\n",
       "71.0        2460\n",
       "38.0        2423\n",
       "33.0        1898\n",
       "29.0        1189\n",
       "25.0         780\n",
       "4.0          529\n",
       "21.0         499\n",
       "17.0         429\n",
       "8.0          348\n",
       "13.0         346\n",
       "175.0        145\n",
       "183.0         39\n",
       "167.0         38\n",
       "192.0         37\n",
       "158.0         15\n",
       "150.0         10\n",
       "125.0          6\n",
       "142.0          4\n",
       "108.0          4\n",
       "117.0          4\n",
       "133.0          3\n",
       "Name: observation_percent, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### This one is different so I will have to handle it manually.\n",
    "pm25.observation_percent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value counts: 100.0    4830845\n",
      "Name: observation_percent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pm25 = pm25.loc[pm25['observation_percent'] == 100]\n",
    "print(f'New value counts: {pm25.observation_percent.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "MemoryError()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3601\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5240\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5241\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5249\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1912\u001b[0m         merged_blocks = _merge_blocks(\n\u001b[1;32m-> 1913\u001b[1;33m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_can_consolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1914\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   3319\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3320\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-35a91681b5a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemperature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_observation_percent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-89c4a71bc10e>\u001b[0m in \u001b[0;36mfilter_observation_percent\u001b[1;34m(df, threshold)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfilter_observation_percent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'observation_percent'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'New value counts: {df.observation_percent.value_counts()}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1797\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1798\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1799\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1800\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1441\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: MemoryError()"
     ]
    }
   ],
   "source": [
    "temperature = filter_observation_percent(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure = filter_observation_percent(pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = filter_observation_percent(wind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate Duplicates in Merge Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_merge_column(data, string):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    dataframe\n",
    "    string\n",
    "    \n",
    "    return dataframe of rows with merge_column entry matching string\n",
    "    \"\"\"\n",
    "    return data.loc[data.merge_column == string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_merge_column(co, 'Alabama-Jefferson-2000-01-0100:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have the column I want to merge my data on but I have multiple entries for some values. I need to eliminate duplicate entries somehow so that each value is unique across all 10 dataframes. \n",
    "\n",
    "The columns that have differences are site_num, sample_duration, pollutant_standard, observation_count, observation_percent, arithmetic_mean, 1st_max_value, 1st_max_hour, aqi, and city_name.\n",
    "\n",
    "I think sample_duration is the easiest column with which to start. I will try filtering all dataframes to just one sample duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter sample_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [co, no2, o3, so2, pm10, pm25, pressure, temperature, wind]:\n",
    "    display(df.sample_duration.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = co.loc[co.sample_duration == '1 HOUR']\n",
    "co.sample_duration.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so2 = so2.loc[so2.sample_duration == '1 HOUR']\n",
    "so2.sample_duration.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm10 = pm10.loc[pm10.sample_duration == '24 HOUR']\n",
    "pm10.sample_duration.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25 = pm25.loc[pm25.sample_duration == '24 HOUR']\n",
    "pm25.sample_duration.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for df in [co, no2, o3, so2, pm10, pm25, pressure, temperature, wind]:\n",
    "    display(df.sample_duration.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of rows in all data\n",
    "total = 0\n",
    "for df in [co, no2, o3, so2, pm10, pm25, pressure, temperature, wind, aqi]:\n",
    "    total += df.shape[0]\n",
    "print(f'There are {total} rows altogether in these dataframes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate data for merge_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_duplicates(dfs):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    dfs = list of dataframes\n",
    "    \n",
    "    Returns\n",
    "    length of each dataframe\n",
    "    number of duplicates in merge_column of each dataframe\n",
    "    percent of duplicates in merge_column of each dataframe\n",
    "    \"\"\"\n",
    "    num = 0\n",
    "    for df in dfs:\n",
    "        print(num)\n",
    "        print(f'Length of dataframe {len(df)}')\n",
    "        duplicates = pd.DataFrame()\n",
    "        duplicates = df[df.duplicated(['merge_column'], keep=False)]\n",
    "        print(f'Number of duplicates in merge_column: {len(duplicates)}')\n",
    "        print(f'Percent of duplicates in merge_column: {len(duplicates)/len(df) * 100}')\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_merge_column(co, 'Alabama-Jefferson-2000-01-0100:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check dataframe for duplicate values in merge_column\n",
    "dfs = [co, no2, o3, so2, pm10, pm25, pressure, \n",
    "       temperature, wind, aqi]\n",
    "check_for_duplicates(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "co.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = ['merge_column', 'state_code', 'county_code', 'state_name', \n",
    "                 'county_name', 'site_num', 'latitude', 'longitude', 'date_local', \n",
    "                 'co_arithmetic_mean', 'no2_arithmetic_mean',  'o3_arithmetic_mean',  \n",
    "                 'so2_arithmetic_mean',  'pm10_arithmetic_mean',  'pm25_arithmetic_mean',  \n",
    "                 'pressure_arithmetic_mean',  'temperature_arithmetic_mean',  'wind_arithmetic_mean', \n",
    "                 'aqi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_columns = ['merge_column', 'state_code', 'county_code', 'state_name', \n",
    "        'county_name', 'site_num', 'poc', 'latitude', 'longitude', \n",
    "        'date_local', 'arithmetic_mean', '1st_max_value', '1st_max_hour', \n",
    "        'aqi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['merge_column', 'state_name', 'county_name', 'date_local', 'state_code', 'county_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_by_county(df, measure):\n",
    "    \"\"\"\n",
    "    Takes average of measures from multiple sites within the same county on the same day\n",
    "    merge_column = state-county-date\n",
    "    \n",
    "    Input:\n",
    "    df - dataframe\n",
    "    measure - string, suffix for name of new column\n",
    "    \"\"\"\n",
    "    keep_columns = ['merge_column', 'state_name', 'county_name', 'date_local']\n",
    "    column_name = str(measure)\n",
    "    aggregate = df.groupby(keep_columns)[\"arithmetic_mean\"].mean()\n",
    "    agg_df = aggregate.to_frame(name=column_name).reset_index()\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_merged = average_by_county(co, 'co')\n",
    "no2_merged = average_by_county(no2, 'no2')\n",
    "o3_merged = average_by_county(o3, 'o3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "co.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_merged.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_merged = average_by_county(so2, 'so2')\n",
    "pm10_merged = average_by_county(pm10, 'pm10')\n",
    "pm25_merged = average_by_county(pm25, 'pm25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_merged = average_by_county(wind, 'wind')\n",
    "temperature_merged = average_by_county(temperature, 'temperature')\n",
    "pressure_merged = average_by_county(pressure, 'pressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wind_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check dataframe for duplicate values in merge_column\n",
    "dfs = [co_merged, no2_merged, o3_merged, so2_merged,\n",
    "       pm10_merged, pm25_merged, pressure_merged, \n",
    "       temperature_merged, wind_merged]\n",
    "check_for_duplicates(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes = [co_merged, no2_merged, o3_merged, so2_merged,\n",
    "       pm10_merged, pm25_merged, pressure_merged, \n",
    "       temperature_merged, wind_merged, aqi]\n",
    "num = 0\n",
    "for df in dataframes: \n",
    "    print(num)\n",
    "    display(df.shape)\n",
    "    display(check_nulls(df, as_percent=True))\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "so2_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format AQI dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aqi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_duplicates([aqi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_short = aqi[['merge_column', 'state_name', 'county_name', 'date_local', 'aqi', 'category', 'defining_parameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aqi_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_merge_column(co_merged, 'Alabama-Baldwin-2000-01-1600:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_merge_column(pm25_merged, 'Alabama-Baldwin-2000-01-1600:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_merge_column(aqi_short, 'Alabama-Baldwin-2000-01-1600:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(df1, df2):\n",
    "    \"\"\"\n",
    "    Merges dateframes on these columns:\n",
    "    'merge_column', 'state_name', 'county_name', 'date_local'\n",
    "    \"\"\"\n",
    "    full_merge = pd.merge(df1, df2, \n",
    "                          on=['merge_column', 'state_name', 'county_name', 'date_local'], \n",
    "                          how='inner')\n",
    "    return full_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = merge_dataframes(o3_merged, co_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = merge_dataframes(merge1, no2_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3 = merge_dataframes(merge2, so2_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge4 = merge_dataframes(merge3, pm10_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge5 = merge_dataframes(merge4, pm25_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge6 = merge_dataframes(merge5, pressure_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge7 = merge_dataframes(merge6, temperature_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge8 = merge_dataframes(merge7, wind_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge = merge_dataframes(merge8, aqi_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.to_csv('final_merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge = pd.merge(o3_merged,co_merged,\n",
    "                      on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge = pd.merge(full_merge,no2_merged[['merge_column', 'no2']],\n",
    "                      on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge = pd.merge(full_merge,so2_merged[['merge_column', 'so2']],\n",
    "                      on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge = pd.merge(full_merge,pm10_merged[['merge_column', 'pm10']],\n",
    "                      on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge = pd.merge(full_merge,pm25_merged[['merge_column', 'pm25']],\n",
    "                      on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge = pd.merge(full_merge,pressure_merged[['merge_column', 'pressure']],\n",
    "                      on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge = pd.merge(full_merge,temperature_merged[['merge_column', 'temperature']],\n",
    "                      on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge = pd.merge(full_merge,wind_merged[['merge_column', 'wind']],\n",
    "                      on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_merge = pd.merge(full_merge,aqi_short[['merge_column', 'aqi']],\n",
    "                       on=['merge_column', 'state_name', 'county_name', 'date_local'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "full_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_duplicates([final_merge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_nulls(final_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = final_merge.dropna(thresh=12)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_rows = final_merge.dropna()\n",
    "full_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_rows.state_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rows.aqi.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rows.loc[full_rows.aqi == 1108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_rows['target'] = pd.cut(x=full_rows['aqi'], bins=[0, 50, 100, 150, 200, 300, 2000], labels=[0,1,2,3,4,5])\n",
    "full_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_rows.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rows.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.to_csv('nonnull_binned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success!\n",
    "\n",
    "I have now combined the 200 files into just 2 files: `merged_data.csv` and `nonnull_binned_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_merge_column(temperature, 'Alaska-Denali-2000-01-0100:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
